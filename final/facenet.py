# -*- coding: utf-8 -*-
"""faceNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aH7v7KJz7y94udpGuISYNKHbqgDflSM1
"""

import numpy as np
import cv2
from keras.models import Model, Sequential
from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation
from PIL import Image
from keras.preprocessing.image import load_img, save_img, img_to_array
from keras.applications.imagenet_utils import preprocess_input
from keras.preprocessing import image
import matplotlib.pyplot as plt
from keras.models import model_from_json
from os import listdir

#-----------------------

face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd croppedAumkar/

def preprocess_image(image_path):
    img = load_img(image_path, target_size=(160, 160))
    img = img_to_array(img)
    img = np.expand_dims(img, axis=0)
    
    #preprocess_input normalizes input in scale of [-1, +1]. You must apply same normalization in prediction.
    #Ref: https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py (Line 45)
    img = preprocess_input(img)
    return img

cd ..

!wget 'https://github.com/serengil/tensorflow-101/blob/master/model/facenet_model.json'

!wget 'https://drive.google.com/file/d/1971Xk5RwedbudGgTIrGAL4F7Aifu7id1/view?usp=sharing'

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My\ Drive/RP PIC/mini

# import os
# #https://github.com/serengil/tensorflow-101/blob/master/model/facenet_model.json
# path= '/content/drive/.shortcut-targets-by-id/1Ehb-EfIeB2rlop-utFrEMI9Z4f1J8unG/RP PIC/mini/facenet_model.json'
# with open(path, 'r') as j:
#      #model = json.loads(j.read())
#      model = model_from_json(j.read())
# print("model built")

# get the following file in the same directoryhttps
#!wget 'https://github.com/serengil/tensorflow-101/blob/master/model/inception_resnet_v1.py'
from inception_resnet_v1 import *
model = InceptionResNetV1()
print("model built")

#https://drive.google.com/file/d/1971Xk5RwedbudGgTIrGAL4F7Aifu7id1/view?usp=sharing
model.load_weights('/content/drive/.shortcut-targets-by-id/1Ehb-EfIeB2rlop-utFrEMI9Z4f1J8unG/RP PIC/mini/facenet_weights.h5')
print("weights loaded")

def findEuclideanDistance(test_representation,source_representation):
    euclidean_distance = source_representation - test_representation
    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))
    euclidean_distance = np.sqrt(euclidean_distance)
    return euclidean_distance

def l2_normalize(x):
 return x / np.sqrt(np.sum(np.multiply(x, x)))

# img1_representation = l2_normalize(model.predict(preprocess_image('/content/drive/.shortcut-targets-by-id/1Ehb-EfIeB2rlop-utFrEMI9Z4f1J8unG/RP PIC/mini/friends/shreya.jpg'))[0,:])
# img2_representation = l2_normalize(model.predict(preprocess_image('/content/drive/.shortcut-targets-by-id/1Ehb-EfIeB2rlop-utFrEMI9Z4f1J8unG/RP PIC/mini/friends/aumkar.jpg'))[0,:])
 
# euclidean_distance = findEuclideanDistance(img1_representation, img2_representation)

db = "/content/drive/.shortcut-targets-by-id/1Ehb-EfIeB2rlop-utFrEMI9Z4f1J8unG/RP PIC/mini/friends"

students_dict = dict()
i=0
for file in listdir(db):
  student, extension = file.split(".")
  #path='/content/drive/.shortcut-targets-by-id/1Ehb-EfIeB2rlop-utFrEMI9Z4f1J8unG/RP PIC/mini/friends/'
  img=os.path.join(db,file)
  cv2_imshow(cv2.imread(img))
  representation = l2_normalize(model.predict(preprocess_image(img)))
  # print(img)
  # print("_________________________________________________________________________________________________________")


  print(student)
  # #i=i+1
  students_dict[student] = representation
	
print("done")

print(students_dict)

!wget https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
!pip install numpy opencv-python dlib imutils
import dlib
import cv2
import os
detector = dlib.get_frontal_face_detector()

db = "/content/drive/.shortcut-targets-by-id/1Ehb-EfIeB2rlop-utFrEMI9Z4f1J8unG/RP PIC/mini/shaney"
threshold=0.35
from google.colab.patches import cv2_imshow

for file in listdir(db):
  student, extension = file.split(".")
  #path='/content/drive/.shortcut-targets-by-id/1Ehb-EfIeB2rlop-utFrEMI9Z4f1J8unG/RP PIC/mini/friends'
  img=os.path.join(db,file)
  
  representation = l2_normalize(model.predict(preprocess_image(img)))
  for x in students_dict:
    
    euclidean_distance = findEuclideanDistance(representation, students_dict[x])
    print(x,euclidean_distance)
    if euclidean_distance<threshold:
      cv2_imshow(cv2.imread(img))
      print(x," is detected")

import os
cu=os.listdir('/content/drive/.shortcut-targets-by-id/1Ehb-EfIeB2rlop-utFrEMI9Z4f1J8unG/RP PIC/mini/aumkar')
for f in cu:
  print(f)
list_of_train_data1 = [f for f in cu if f.endswith('.jpg')]
print(list_of_train_data1)

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/.shortcut-targets-by-id/1Ehb-EfIeB2rlop-utFrEMI9Z4f1J8unG/RP PIC/mini/aumkar

from google.colab.patches import cv2_imshow

threshold = 21

for vid in list_of_train_data1:
    print(vid)
    img=cv2.imread(os.path.join('',vid))
    faces = face_cascade.detectMultiScale(img, 1.3, 5)
    for (x,y,w,h) in faces:
      cv2.rectangle(img, (x,y), (x+w,y+h), (67, 67, 67), 1) #draw rectangle to main image

      detected_face = img[int(y):int(y+h), int(x):int(x+w)]
      detected_face= cv2.resize(detected_face, (160, 160))
      cv2_imshow(detected_face)
      img_pixels = image.img_to_array(detected_face)
      img_pixels = np.expand_dims(img_pixels, axis = 0)
      #employee dictionary is using preprocess_image and it normalizes in scale of [-1, +1]
      img_pixels /= 127.5
      img_pixels -= 1

      captured_representation = model.predict(img_pixels)
      print(captured_representation)
      distances = []

      for i in students_dict:
          name = i
          source_representation = students_dict[i]
          
          distance = findEuclideanDistance(captured_representation, source_representation)
          
          print(name,": ",distance)
          distances.append(distance)
        
			
      label_name = 'unknown'
      index = 0
      for i in students_dict:
        name = i
        if index == np.argmin(distances):
          if distances[index] <= threshold:
            print("detected: ",name)
            
            #label_name = "%s (distance: %s)" % (employee_name, str(round(distance,2)))
            similarity = 100 + (20 - distance)
            if similarity > 99.99: similarity = 99.99
            
            label_name = "%s (%s%s)" % (name, str(round(similarity,2)), '%')
            
            break
          
        index = index + 1
			
      cv2.putText(img, label_name,(int(x+w+15), int(y-64)), cv2.FONT_HERSHEY_SIMPLEX, 1, (67,67,67), 1)
          
      #connect face and text
      cv2.line(img,(x+w, y-64),(x+w-25, y-64),(67,67,67),1)
      cv2.line(img,(int(x+w/2),y),(x+w-25,y-64),(67,67,67),1)

      cv2_imshow(img)

import os
cu=os.listdir('/content/drive/.shortcut-targets-by-id/1Ehb-EfIeB2rlop-utFrEMI9Z4f1J8unG/RP PIC/mini/jinang')
list_of_train_data2 = [f for f in cu if f.endswith('.jpg')]
print(list_of_train_data2)

# Commented out IPython magic to ensure Python compatibility.
# %cd ..
# %cd jinang

from google.colab.patches import cv2_imshow

threshold = 21
path='/content/gdrive/.shortcut-targets-by-id/923/RP PIC/mini/aumkar'
for vid in list_of_train_data2:
    
    img=cv2.imread(os.path.join('',vid))
    faces = face_cascade.detectMultiScale(img, 1.3, 5)
    for (x,y,w,h) in faces:
      cv2.rectangle(img, (x,y), (x+w,y+h), (67, 67, 67), 1) #draw rectangle to main image

      detected_face = img[int(y):int(y+h), int(x):int(x+w)]
      detected_face= cv2.resize(detected_face, (160, 160))
      img_pixels = image.img_to_array(detected_face)
      img_pixels = np.expand_dims(img_pixels, axis = 0)
      #employee dictionary is using preprocess_image and it normalizes in scale of [-1, +1]
      img_pixels /= 127.5
      img_pixels -= 1

      captured_representation = model.predict(img_pixels)[0,:]

      distances = []

      for i in students_dict:
          name = i
          source_representation = students_dict[i]
          
          distance = findEuclideanDistance(captured_representation, source_representation)
          
          print(name,": ",distance)
          distances.append(distance)
        
			
      label_name = 'unknown'
      index = 0
      for i in students_dict:
        name = i
        if index == np.argmin(distances):
          if distances[index] <= threshold:
            print("detected: ",name)
            
            #label_name = "%s (distance: %s)" % (employee_name, str(round(distance,2)))
            similarity = 100 + (20 - distance)
            if similarity > 99.99: similarity = 99.99
            
            label_name = "%s (%s%s)" % (name, str(round(similarity,2)), '%')
            
            break
          
        index = index + 1
			
      cv2.putText(img, label_name,(int(x+w+15), int(y-64)), cv2.FONT_HERSHEY_SIMPLEX, 1, (67,67,67), 1)
          
      #connect face and text
      cv2.line(img,(x+w, y-64),(x+w-25, y-64),(67,67,67),1)
      cv2.line(img,(int(x+w/2),y),(x+w-25,y-64),(67,67,67),1)

      cv2_imshow(img)

